<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Análisis Factorial Confirmatorio y Confiabilidad en R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Brian N. Peña-Calero y Arnold Tafur-Mendoza" />
    <meta name="date" content="2019-12-10" />
    <script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
    <script src="libs/viz-1.8.2/viz.js"></script>
    <link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
    <script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <script src="libs/jquery-1.12.4/jquery.min.js"></script>
    <link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding-0.13/datatables.js"></script>
    <link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
    <link rel="stylesheet" href="amp.css" type="text/css" />
    <link rel="stylesheet" href="amp-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Análisis Factorial Confirmatorio y Confiabilidad en <code>R</code>
## 3er CIEP - Usil
### Brian N. Peña-Calero y Arnold Tafur-Mendoza
### Avances en Medición Psicológica (AMP) - UNMSM
### 12/10/2019

---

class: inverse, center, middle

# .font150[**Temario**]

---

# Temario

1. Modelos Factoriales
 * Definición y utilidad 
 * Conceptos: cargas factoriales, errores, variables observables, variables latentes. 
1. Análisis Factorial Confirmatorio
 * Diferencias y usos entre el análisis factorial exploratorio y confirmatorio
 * Concepto y utilidad
 * Términos básicos: Estimación restringidas (correlación de errores), liberadas, fijas 
 * Modelos AFC conocidos: Primer orden (ortogonales y oblicuos), segundo orden, bifactor
 * Procedimientos de análisis: Especificación, Identificación, Estimación, evaluación y re-especificación
 * Ejemplificación con caso
1. Fiabilidad por consistencia interna
 * Problemática de Alfa y la tau-equivalencia
 * Ventajas de la fiabilidad basado en modelos factoriales
 * Procedimiento en software

---
class: inverse, center, middle

# .font120[**Modelos Factoriales**]

---

# Modelos Factoriales

## Definición y Utilidad
## Conceptos
* ### Cargas Factoriales
* ### Errrores
* ### Variables Observables
* ### Variables Latentes

---
class: inverse, center, middle

# .font120[**Análisis Factorial Confirmatorio**]
---

# Análisis Factorial Confirmatorio
* ### Diferencias y usos entre el análisis factorial exploratorio y confirmatorio
* ### Concepto y utilidad
* ### Términos básicos: Estimación restringidas (correlación de errores), liberadas, fijas
* ### Modelos AFC conocidos: Primer orden (ortogonales y oblicuos), segundo orden, bifactor

---
# Procedimientos de análisis
&lt;br&gt;
## 1. Especificación 
## 2. Identificación
## 3. Estimación
## 4. Evaluación 
## 5. Re-especificación

---
# Procedimientos de análisis

## 1. Especificación 
.left-plot[
<div id="htmlwidget-316fe1e13f9b7939842c" style="width:500px;height:550px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-316fe1e13f9b7939842c">{"x":{"diagram":"\ndigraph rmarkdown {\ngraph [layout = neato,\noverlap = true,\noutputorder = edgesfirst] \n\nnode [shape = rectangle]\na [pos = \"-5.0, 0.5!\",  label = \"Variable \n Latente\", shape = circle]\nb [pos = \"-3.0, -0.8!\", label = \"Item03\"]\nc [pos = \"-3.0, 0.5!\",  label = \"Item02\"]\nd [pos = \"-3.0, 1.8!\",  label = \"Item01\"]\ne [pos = \"-2.0, -0.8!\", label = \"e3\", shape = circle, fixedsize = TRUE, width = 0.4]\nf [pos = \"-2.0, 0.5!\",  label = \"e2\", shape = circle, fixedsize = TRUE, width = 0.4]\ng [pos = \"-2.0, 1.8!\",  label = \"e1\", shape = circle, fixedsize = TRUE, width = 0.4]\n\na -> d [tailport = \"e\", headport = \"w\"]\na -> c [tailport = \"e\", headport = \"w\"]\na -> b [tailport = \"e\", headport = \"w\"]\ne -> b\nf -> c\ng -> d\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
]

.right-code[&lt;br&gt; `lavaan` automatiza la asignación de los errores pertenecientes a cada variable observada (ítem). &lt;br&gt;

```r
model &lt;- " # Modelo de Medición
          `Variable Latente` =~ Item01 + Item02 + Item03
         "
```
Se crea (`&lt;-`) el objeto `model` donde se **especifica**:
* Cuántas y como se llaman las variables latentes
* Cuántos ítems y a donde pertenecen

.center[.font100[*¡Veamos como sería en un modelo más complejo!*]]
]

---
# Procedimientos de análisis

## 1. Especificación 
.left-plot[
<div id="htmlwidget-d75ba1269856ea613540" style="width:450px;height:520px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-d75ba1269856ea613540">{"x":{"diagram":"\ndigraph rmarkdown {\ngraph [layout = neato,\noverlap = true,\noutputorder = edgesfirst] \n\nnode [shape = rectangle]\n\n# Primer Factor\na [pos = \"-5.0, 1.2!\",  label = \"VL1\", shape = ellipse]\nb [pos = \"-3.0, 0.6!\", label = \"Item03\"]\nc [pos = \"-3.0, 1.2!\",  label = \"Item02\"]\nd [pos = \"-3.0, 1.8!\",  label = \"Item01\"]\ne [pos = \"-2.0, 0.6!\", label = \"e3\", shape = circle, fixedsize = TRUE, width = 0.4]\nf [pos = \"-2.0, 1.2!\",  label = \"e2\", shape = circle, fixedsize = TRUE, width = 0.4]\ng [pos = \"-2.0, 1.8!\",  label = \"e1\", shape = circle, fixedsize = TRUE, width = 0.4]\n\n# Segundo Factor\nm [pos = \"-5.0, -0.9!\",  label = \"VL2\", shape = ellipse]\nn [pos = \"-3.0, -0.3!\", label = \"Item04\"]\no [pos = \"-3.0, -0.9!\",  label = \"Item05\"]\np [pos = \"-3.0, -1.5!\",  label = \"Item06\"]\nq [pos = \"-2.0, -0.3!\", label = \"e4\", shape = circle, fixedsize = TRUE, width = 0.4]\nr [pos = \"-2.0, -0.9!\",  label = \"e5\", shape = circle, fixedsize = TRUE, width = 0.4]\ns [pos = \"-2.0, -1.5!\",  label = \"e6\", shape = circle, fixedsize = TRUE, width = 0.4]\n\n\n\na -> d [tailport = \"e\", headport = \"w\"]\na -> c [tailport = \"e\", headport = \"w\"]\na -> b [tailport = \"e\", headport = \"w\"]\ne -> b\nf -> c\ng -> d\n\nm -> n [tailport = \"e\", headport = \"w\"]\nm -> o [tailport = \"e\", headport = \"w\"]\nm -> p [tailport = \"e\", headport = \"w\"]\nq -> n\nr -> o\ns -> p\n\na -> m [dir = both]\n\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
]

.right-code[El símbolo .font150[`↔`] hace referencia a la ***covarianza*** entre los factores. 

```r
model &lt;- " # Modelo de Medición
          VL1 =~ Item01 + Item02 + Item03
          VL2 =~ Item04 + Item05 + Item06
          # VL1 ~~ VL2
         "
```
No es necesario especificar `VL1 ~~ VL2`. `lavaan` supone que siempre trabajamos con modelos oblicuos. 

**Nota:** *Más adelante veremos modelos ortogonales.*
]

---
# Procedimientos de análisis

## 1. Especificación 

Hay más cosas que podemos especificar en nuestros modelos de medición:

--
* Igualar las cargas factoriales de alguno o varios ítems

--

```r
VL1 =~ a*Item01 + a*Item02 + a*Item03
```

--
* Especificar modelos ortogonales

--

```r
VL1 ~~ 0*VL2
```

--
* Realizar correlación entre errores (covarianza de varianza específica de los ítems)

--

```r
# Correlación de errores
  Item01 ~~ Item02 
```

---
# Procedimientos de análisis

## 1. Especificación 
.left-plot[
<div id="htmlwidget-54be0d130646b5086701" style="width:450px;height:520px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-54be0d130646b5086701">{"x":{"diagram":"\ndigraph rmarkdown {\ngraph [layout = neato,\noverlap = true,\noutputorder = edgesfirst] \n\nnode [shape = rectangle]\n\n# Primer Factor\na [pos = \"-5.0, 1.2!\",  label = \"VL1\", shape = ellipse]\nb [pos = \"-3.0, 0.6!\", label = \"Item03\"]\nc [pos = \"-3.0, 1.2!\",  label = \"Item02\"]\nd [pos = \"-3.0, 1.8!\",  label = \"Item01\"]\ne [pos = \"-2.0, 0.6!\", label = \"e3\", shape = circle, fixedsize = TRUE, width = 0.4]\nf [pos = \"-2.0, 1.2!\",  label = \"e2\", shape = circle, fixedsize = TRUE, width = 0.4]\ng [pos = \"-2.0, 1.8!\",  label = \"e1\", shape = circle, fixedsize = TRUE, width = 0.4]\n\n# Segundo Factor\nm [pos = \"-5.0, -0.9!\",  label = \"VL2\", shape = ellipse]\nn [pos = \"-3.0, -0.3!\", label = \"Item04\"]\no [pos = \"-3.0, -0.9!\",  label = \"Item05\"]\np [pos = \"-3.0, -1.5!\",  label = \"Item06\"]\nq [pos = \"-2.0, -0.3!\", label = \"e4\", shape = circle, fixedsize = TRUE, width = 0.4]\nr [pos = \"-2.0, -0.9!\",  label = \"e5\", shape = circle, fixedsize = TRUE, width = 0.4]\ns [pos = \"-2.0, -1.5!\",  label = \"e6\", shape = circle, fixedsize = TRUE, width = 0.4]\n\n\n\na -> d [tailport = \"e\", headport = \"w\"]\na -> c [tailport = \"e\", headport = \"w\"]\na -> b [tailport = \"e\", headport = \"w\"]\ne -> b\nf -> c\ng -> d\n\nm -> n [tailport = \"e\", headport = \"w\"]\nm -> o [tailport = \"e\", headport = \"w\"]\nm -> p [tailport = \"e\", headport = \"w\"]\nq -> n\nr -> o\ns -> p\n\na -> m [dir = both]\nq -> r [dir = both]\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
]

.right-code[¡ A resolverlo!]

--
.right-code[

```r
model &lt;- " # Modelo de Medición
           VL1 =~ Item01 + Item02 + Item03
           VL2 =~ Item04 + Item05 + Item06
           
           # Correlación de errores
           Item04 ~~ Item05
         "
```
La varianza específica del `Item04` y del `Item05` son los que se relacionan de alguna manera. Existe algo que distinto a `VL2` que está explicando el comportamiento de las puntuaciones de esos ítems.
]

---
# Procedimientos de análisis

## 2. Identificación

Este procedimiento hace referencia a la suficiencia de información para el análisis. Dependiendo de la cantidad de información que tengamos y que solicitemos, podremos encontrar una solución satisfactoria.
Por ejemplo:

&lt;box-block&gt; 
X + Y  = 20 &lt;br&gt;
2X + Y = 28 
&lt;/box-block&gt;

¿Cuánto vale `X` y cuánto vale `Y`?

--
&lt;br&gt; `X = 8`
&lt;br&gt; `Y = 12`

.center[.font120[*¿Había suficiente información?*]]

---
# Procedimientos de análisis

## 2. Identificación

Imaginemos ahora la siguiente situación:

&lt;box-block&gt; 
 X + Y  = 25 &lt;br&gt;
2X + 2Y = 50
&lt;/box-block&gt;

¿Cuánto vale `X` y cuánto vale `Y`?

-- 
Las soluciones pueden ser infinitas
&lt;br&gt; `X = 10; Y = 15`
&lt;br&gt; `X = 8; Y = 17`
&lt;br&gt; `X = 15; Y = 10`

.center[.font120[*¡No tenemos suficiente información!*]]

---
# Procedimientos de análisis

## 2. Identificación

En el caso de un `AFC` la suficiencia de información hace referencia a la cantidad de correlaciones que existe en una matriz de las variables a analizar (en nuestros casos, los ítems). Esto se contrasta con la información solicitada (`Especificaciòn`).




```
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
```

```
##   rowname   x1   x2   x3
## 1      x1 1.00          
## 2      x2  .30 1.00     
## 3      x3  .44  .34 1.00
```

.center[.font110[¿Cuántas correlaciones tenemos?]]

--
.center[`6`]

---
# Procedimientos de análisis

## 2. Identificación

Veamos otro ejemplo con una cantidad de ítems mayor


```
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
```

```
##   rowname   x1   x2   x3   x4   x5
## 1      x1 1.00                    
## 2      x2  .30 1.00               
## 3      x3  .44  .34 1.00          
## 4      x4  .37  .15  .16 1.00     
## 5      x5  .29  .14  .08  .73 1.00
```

.center[.font110[¿Cuántas correlaciones tenemos?]]

--
.center[`15`]

---
# Procedimientos de análisis

## 2. Identificación

¡Último ejemplo! *Nota: Encuentren la regla*

.left-code[

```
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
```

```
##   rowname   x1   x2   x3   x4   x5   x6   x7   x8
## 1      x1 1.00                                   
## 2      x2  .30 1.00                              
## 3      x3  .44  .34 1.00                         
## 4      x4  .37  .15  .16 1.00                    
## 5      x5  .29  .14  .08  .73 1.00               
## 6      x6  .36  .19  .20  .70  .72 1.00          
## 7      x7  .07 -.08  .07  .17  .10  .12 1.00     
## 8      x8  .22  .09  .19  .11  .14  .15  .49 1.00
```
]

.right-code[
.center[.font110[¿Cuántas correlaciones tenemos?]]
&lt;br&gt; .center[`36`]
&lt;br&gt;
.center[$$Información= \frac{n(n+1)}{2}$$]
]

---
# Procedimientos de análisis

## 2. Identificación
.left-plot[
<div id="htmlwidget-df71511900894b990f89" style="width:500px;height:550px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-df71511900894b990f89">{"x":{"diagram":"\ndigraph rmarkdown {\ngraph [layout = neato,\noverlap = true,\noutputorder = edgesfirst] \n\nnode [shape = rectangle]\na [pos = \"-5.0, 0.5!\",  label = \"Variable \n Latente\", shape = circle]\nb [pos = \"-3.0, -0.8!\", label = \"Item03\"]\nc [pos = \"-3.0, 0.5!\",  label = \"Item02\"]\nd [pos = \"-3.0, 1.8!\",  label = \"Item01\"]\ne [pos = \"-2.0, -0.8!\", label = \"e3\", shape = circle, fixedsize = TRUE, width = 0.4]\nf [pos = \"-2.0, 0.5!\",  label = \"e2\", shape = circle, fixedsize = TRUE, width = 0.4]\ng [pos = \"-2.0, 1.8!\",  label = \"e1\", shape = circle, fixedsize = TRUE, width = 0.4]\n\na -> d [tailport = \"e\", headport = \"w\", label = \"λ1\"]\na -> c [tailport = \"e\", headport = \"w\", label = \"λ2\"]\na -> b [tailport = \"e\", headport = \"w\", label = \"λ3\"]\ne -> b [label = c]\nf -> c [label = b]\ng -> d [label = a]\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
]

.right-code[¿Cuánta información estamos solicitando aquí? 
En total, solicitamos calcular las `cargas factoriales` (*varianza común*) y el `error de medición` (*varianza específica*):
&lt;br&gt; Cargas factoriales: `λ1, λ2, λ3`
&lt;br&gt; Error de medición: `a, b, c`

.center[*Entonces estamos solicitando 6 informaciones*]

Siendo 3 ítems que ingresan al modelo. 
&lt;br&gt; &lt;br&gt;
.center[**¿De cuánta información disponemos?**]
]

---
# Procedimientos de análisis

## 2. Identificación
### Notas importantes
* Mientras tengamos más de 3 ítems en nuestro modelo, no tendremos problemas de identificación (*sub-identificación* o *no identificado*). 
* En los casos que tenemos modelos con solo 3 ítems, se puede calcular siempre y cuando no se soliciten mayor información (*apenas identificado*) como por ejemplo, `correlación de errores entre ítems`. Debido a que con 3 ítems tenemos 6 cantidad de informaciones y estaríamos solicitando un total de 7 informaciones.
* No es imposible trabajar con modelos de 2 o 1 ítem (*ítems únicos*), siempre y cuando se empleen algunos artificios. Por ejemplo, igualar cargas factoriales o ingresar información previa sobre algún parámetro (de esta manera no se volverá a calcular).

---
# Procedimientos de análisis

## 3. Estimación

.center[&lt;b&gt;Tabla Resumen de Estimadores&lt;/b&gt;]
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Estimadores &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Estimadores Robustos &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Descripciones &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ML (Máxima Verosimilitud) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; MLM, MLR, MLMVS, MLMV &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Datos continuos &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ULS (Mínimos cuadrados no ponderados) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ULSM, ULSMVS, ULSMV &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Variables Categóricas &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; WLS (Mínimos cuadrados ponderados) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; - &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Variables Categóricas &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; DWLS (Mínimos cuadrados con diagonal ponderada &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; WLSM, WLSMVS, WLSMV &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Variables Categóricas. Es el más recomendado en la actualidad &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# Procedimientos de análisis

## 3. Estimación

Aclaración sobre los sufijos de las nomenclaturas para los **estimadores robustos**:
* ABC`M`: Trabaja con errores robustos y corrección para chi-cuadrado *Satorra-Bentler*
* ABC`MVS`: Trabaja con errores robustos y corrección para media-varianza y chi-cuadrado *Satterthwaite*
* ABC`MV`: Trabaja con errores robustos y corrección para media-varianza y chi-cuadrado *scale-shifted*

Los estudios de simulación coinciden en que la corrección **scale-shifted** es quien brinda mejores resultados siempre y cuando se tenga una cantidad de datos *suficiente* (n &gt; 250, dependiendo de la cantidad de ítems).
&lt;br&gt;
Para nuestros casos: Los mejores estimadores a utilizar cuando trabajemos con datos contínuos será `MLR` (en caso de no-normalidad) y `WLSMV` (en caso de datos categóricos).

---
# Procedimientos de análisis

## 4. Evaluación

Este procedimiento hace referencia al cálculo y valoración de los ***índices de ajuste*** de los modelos estimados, así como a las cargas factoriales calculadas.
* Estos índices son derivados del test *chi-cuadrado* por lo que a medida que cambie este, el resto de los índices cambiará. 
* A medida que se emplee un estimador diferente (*recordar que hace correcciones a esta prueba*) y/o aumenten o desciendan el número de ítems/factores, los índices de ajuste cambiarán. 
* Por último a medida que se ingresen o resten especificaciones al modelo, los **índices de ajuste** cambiarán.

Este procedimiento nos permitirá tomar la decisión de finalizar el análisis en este punto o ir al siguiente paso ***Re-Especificación***.

---
# Procedimientos de análisis

## 4. Evaluación

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Índices de ajuste &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Descriptivos &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Puntos de Corte &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; χ² &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Test Chi-Cuadrado (bondad de ajuste) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; No estadísticamente significativo &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; χ²/gl &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Medida de parsimonia &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Menor a 3 o 2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; CFI (Comparative Fit Index) &lt;/td&gt;
   &lt;td style="text-align:center;vertical-align: middle !important;" rowspan="2"&gt; Medida de ajuste independiente o incremental &lt;/td&gt;
   &lt;td style="text-align:center;vertical-align: middle !important;" rowspan="2"&gt; ≥ .90 = ajuste adecuado; ≥ .95 = buen ajuste &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; TLI (Tucker Lewis Index) o NNFI (Non-Normed Fit Index) &lt;/td&gt;
   
   
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; RMSEA (Root Mean Square Error of Approximation) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Evalúa que tan lejos está de un modelo perfecto &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ≥ .10 = ajuste pobre; ≤ .08 = adecuado ajuste, 
                        ≤ .05 = buen ajuste &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; SRMR (Standardized Root Mean Residual) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Evalúa que tan grande es el error de reproducir el modelo &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ≤ .08 = buen ajuste, ≤ .06: ideal &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# Procedimientos de análisis

## 5. Re-Especificación

Este procedimiento hace referencia a empezar nuevamente el flujo del análisis, quitar, aumentar algo en el proceso de `Espeficación` que permita tener un modelo factorial idóneo.

Una de las cosas que ayudan en esta etapa es el cálculo de los `índices de modificación`.
En el paquete `lavaan` podremos realizar rápidamente con la sintaxis:

```r
modificationindices()
```

--
&lt;br&gt;
.center[.font150[¿Listos para hacer un ejemplo?]]

---

# Ejemplificación de caso

Para este primer ejemplo usaremos la BD de Holzinger &amp; Swineford (1939). Se tienen 9 pruebas que se estructuran en 3 factores latentes: Visual, Textual y Velocidad.

```r
lavaan::HolzingerSwineford1939
```
<div id="htmlwidget-6aa8e98e1ef8a5b9d878" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6aa8e98e1ef8a5b9d878">{"x":{"filter":"none","fillContainer":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","261","262","263","264","265","266","267","268","269","270","271","272","273","274","275","276","277","278","279","280","281","282","283","284","285","286","287","288","289","290","291","292","293","294","295","296","297","298","299","300","301"],[1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,33,34,35,36,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,54,55,56,57,58,60,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,85,86,87,88,89,90,91,93,94,95,96,97,98,99,100,101,102,103,104,105,106,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,129,130,131,132,133,134,135,136,137,138,139,140,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,162,163,164,165,166,167,168,201,202,203,204,205,206,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,320,321,322,323,324,325,326,327,328,329,330,331,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,351],[1,2,2,1,2,2,1,2,2,2,1,1,2,2,1,2,2,1,2,2,1,1,1,2,1,1,1,2,2,2,2,1,2,2,2,1,1,2,2,1,2,2,2,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1,2,1,2,2,2,2,2,2,1,2,2,1,2,1,1,1,2,2,1,1,2,1,1,1,1,2,2,2,2,2,2,2,1,2,1,1,1,1,1,2,2,1,1,2,1,1,1,2,2,2,2,2,1,2,1,2,1,2,1,1,1,1,2,1,2,2,1,2,2,2,2,1,1,2,2,2,1,1,1,1,2,2,2,2,1,2,2,2,2,2,1,1,1,1,1,2,2,2,1,2,1,1,1,2,2,2,2,2,1,1,1,2,1,1,2,1,2,2,1,1,2,1,2,2,1,2,1,1,2,1,1,1,1,2,2,2,2,2,2,1,1,2,2,2,2,1,2,2,1,1,2,1,2,2,1,2,2,1,2,1,1,2,1,2,2,2,2,1,2,1,1,1,2,2,2,1,2,1,2,2,2,1,1,2,2,1,2,1,1,1,2,2,2,1,2,2,2,1,1,1,2,2,2,1,2,1,2,1,2,1,2,2,2,1,2,2,1,1,1,1,1,1,1,1,2,1,2,1,1,1,2,1,1,1,2,1,2,1,1,2,2,1,1],[13,13,13,13,12,14,12,12,13,12,12,12,12,12,12,12,14,13,12,12,14,12,12,12,12,12,12,13,12,12,12,16,12,12,13,13,12,12,12,12,12,13,13,14,14,13,13,13,12,13,13,12,15,13,12,14,16,13,14,15,12,12,12,13,13,12,14,13,13,12,14,13,13,13,12,13,12,16,14,14,14,13,14,13,14,12,13,13,13,13,13,14,15,13,14,13,13,13,13,13,15,13,13,13,15,12,13,13,14,13,13,13,13,14,14,13,16,13,13,16,14,15,14,15,14,15,13,13,13,14,13,14,15,13,14,13,13,13,14,14,14,14,15,12,15,13,13,15,14,15,13,15,14,15,15,15,13,11,12,11,12,12,12,11,12,12,12,12,12,12,12,13,12,13,12,12,12,12,12,14,12,12,12,14,13,12,12,12,12,13,12,12,11,13,12,12,12,12,12,12,12,12,12,12,11,12,11,14,12,13,12,12,11,12,12,13,12,12,12,13,13,14,12,13,12,12,12,13,12,11,14,12,12,12,12,14,13,12,13,13,13,13,13,13,14,13,13,13,13,12,13,14,14,15,13,13,13,13,13,13,12,14,13,13,13,13,13,12,13,13,13,15,13,14,14,13,13,14,14,16,12,13,14,14,14,16,13,14,13,14,15,14,12,14,13,13,13,14,14,14,13],[1,7,1,2,2,1,1,2,0,5,2,11,7,8,6,1,11,5,8,3,10,9,11,8,3,7,8,2,5,2,7,0,2,3,3,10,9,8,6,5,1,6,8,8,2,7,5,6,11,2,7,4,7,4,8,4,2,3,0,3,5,9,10,11,1,11,11,0,9,8,2,3,1,7,9,9,6,7,7,1,11,7,5,2,7,11,8,3,11,10,10,0,4,8,10,8,4,2,11,4,3,10,3,4,3,10,5,10,5,3,4,1,4,0,5,1,0,10,4,5,4,1,4,8,5,4,11,11,4,1,11,1,3,6,7,4,10,2,2,7,0,9,0,9,8,6,8,8,4,1,11,5,1,1,7,6,0,10,6,11,5,6,8,11,5,5,0,10,9,8,9,1,1,1,7,1,9,8,6,0,3,4,9,7,2,5,0,0,6,2,0,10,11,8,7,4,6,6,1,9,3,4,10,5,11,8,11,1,4,2,3,11,5,4,0,11,4,9,10,7,2,0,11,0,8,3,0,2,7,4,0,9,5,9,7,2,1,11,2,6,9,2,1,8,2,8,6,7,3,10,5,6,9,11,9,1,9,7,0,8,9,10,5,4,6,6,5,1,5,2,7,3,3,4,7,3,8,6,9,4,11,1,1,3,9,1,5,3,1,4,6,11,11,3,0,3,5,10,3,2,5],["Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Pasteur","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White","Grant-White"],[7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,null],[3.33,5.33,4.5,5.33,4.83,5.33,2.83,5.67,4.5,3.5,3.67,5.83,5.67,6,5.83,4.67,4.33,5,5.67,6.33,5.83,6.67,5,3.83,5.67,5.33,5.5,6,4.67,5,3.5,3,5,4.17,3.33,4.83,5.5,3.83,6.33,5.83,3.83,3.17,1.83,4.17,6.33,6,7.17,3.17,4.33,4.5,5.5,7,3.83,5.17,5,5.67,4,5.83,3.83,4.17,5.33,4,5.33,5.33,3.67,6.5,4,4.67,2.83,4.67,0.67,4.33,5,5,4.17,3.83,5.67,1.67,6.33,4,4.5,4.67,4.83,4.83,3,6.33,5.5,5.33,3.33,5.5,4,3.83,5.17,4.33,4.17,5,4.33,7.5,5,5.5,6.17,6.5,4.33,4.67,6.83,4.5,6.83,5.5,6.33,4.17,5.67,6.33,6.17,5.17,4.17,4.17,5.17,4.33,3.5,4.67,4.83,5,7.5,5.33,6.17,5.33,4.33,4.83,6,5,4.17,5.67,5,3.5,7.33,6.17,4.83,5.67,5.5,5.17,3.17,5,7.17,7.33,2,3.83,4.17,4.67,5.83,6.67,6.83,5.33,4.83,5.17,6.33,4.83,3.83,5.5,5.67,4.83,2.67,5,6,4.67,5,3.33,4.5,5.33,6.33,2.83,5.67,4.17,5.5,6.67,5,6,4,6.67,5,7,5.5,5.33,5.17,4.5,5.17,5.17,2.83,5,4.67,3.17,4.67,6.33,5.67,3,2.67,3,5.33,5.67,3.5,4.67,6.5,5.33,4.67,4,5.17,4.83,4.83,2.67,4.17,4.17,6.17,5,4.83,6.17,4.67,3.67,6.33,4.83,4.17,4.67,3.83,1.83,7.5,3.17,6.83,5.83,5.67,3.17,4.17,6,3.17,4.5,3.5,4.5,4.33,3.33,5.5,6.33,5.5,6,6.33,5.17,6,5.17,4.67,6.33,4.83,5.83,5.83,3.83,5.17,8.5,5.5,3.5,6.17,6.17,6.17,6.5,6.5,3,4.67,4.83,4.17,4.83,5.33,5,5.83,2.67,6.33,4.33,5.5,4.67,4.5,4.33,5,3.67,5.33,5.17,5.33,6.67,3.5,5.17,4,6.83,5,5.83,5.67,4.17,4,6,3.33,4.67,5.67,5.67,5.83,6.17,4,3,4.67,4.33,4.33],[7.75,5.25,5.25,7.75,4.75,5,6,6.25,5.75,5.25,5.75,6,4.5,5.5,5.75,4.75,4.75,6.75,5.25,8.75,8,8.5,6.25,5.5,5.5,4,5.25,5,6,4.5,5.75,6,5.25,6,3.75,5.25,7,4.5,4,7.75,5.75,5,5.25,5.25,5.5,5.5,8.5,4.75,5.5,6.25,5.75,6,7.5,4.75,6,5.25,4.75,5.25,6.5,5.75,5.75,6,6.75,5,5.75,6,9.25,5.75,5,5,4.5,9.25,4.5,6,5.25,5.25,7,5.75,5.5,5.25,6,8,8.25,6.5,5.25,6.25,7,6,7.25,5,6.5,6.25,4.75,3.5,5.5,5.75,4.75,7.5,3.75,6.25,3.75,6.5,7.75,5.25,9,6.5,6.5,6.75,5.5,4.25,9.25,5.25,6.25,6.5,7.5,5.75,5.75,5.25,7.25,4.75,6,5.5,7,5.25,6.75,8.75,7,7,7.5,4.5,8,5.5,6.25,5.25,8,7.5,5.25,6.25,6.75,5,3.75,7.5,9,6.75,5.5,5.5,6,5.75,4.75,5.5,7.25,4.75,5,6,6.75,5.75,4.75,5.5,6,5.75,6.25,6.25,8.25,6.25,6.25,6.25,6.5,5.25,7.75,5.25,7,7.75,7.75,5.75,5.5,7,4,6.5,6,6.75,6.75,5.5,5.25,5.75,5.75,8.5,7.5,5,4.75,5.5,5,6.25,7,5.5,5,7.5,5.25,5.25,5.5,5,6,6.5,6,5,4.75,6.5,7.5,5.75,6.25,6.75,7.75,6.5,6,8.5,5,8.5,5.25,5.25,6.25,6.75,5,5,9.25,3.75,5.25,7.5,6,5.5,5.25,7,5.75,5.25,2.25,5.5,5.5,6.75,5.5,6.5,6.25,7.25,7.25,6.25,7,6.5,6,9.25,8.5,6,6.25,5.25,7,6.5,7,6.5,8,5,6.5,6.5,8.5,4,7,5.75,5,8.25,5.25,5.25,7,8.5,7.5,6.25,7,6.75,5.5,7.25,8,5.75,6,5.75,6.25,5.25,5,6.25,6,6.25,5.75,5,6.75,5.5,6.25,6.5,4.75,6,5.5,5.25,7,6.5,7,6,5.5,6.75,6],[0.38,2.12,1.88,3,0.88,2.25,1,1.88,1.5,0.75,2,2.88,4.12,1.75,3.62,2.38,1.5,2.25,4,3,2,4.12,1.88,1.62,1.25,3.38,4.5,2.12,4.25,0.75,1.38,0.25,1.75,2.38,1.5,0.5,3.5,2.25,3.88,2.5,1.62,1.25,1,1.88,2.75,4.5,4,1.38,2.75,1.12,3.75,2.12,3.25,1.75,4.12,2.12,3.25,3.88,2,1.75,3.38,3.62,1.38,1.25,3.62,2.5,4,3.62,0.88,0.75,0.75,3.38,2.62,3.25,2.12,2.38,2.12,1.38,4.12,2.5,1.75,4.25,2.25,1.75,0.62,2.5,2.88,2.75,3.25,2.25,2.62,3.38,2.12,0.88,0.88,4.25,0.5,2.12,1.38,2.75,4.38,1.88,1.88,1.62,4.38,3.12,0.75,3.75,1.62,2.25,4.38,2.62,4.25,1.75,3.88,1,2.5,4,3.38,1.62,1.5,2.38,4.25,4.12,4.12,3.12,1,1.12,3.25,1.62,4.38,3.5,1.75,2.25,2.62,3.62,4.5,2.75,4.5,2.5,1.5,4.5,3.88,4,0.62,1.88,1.25,1.62,2.62,4.38,4.25,2.62,2.38,2.38,1.12,1.25,0.5,2.12,2.75,1.12,1.25,2.5,4.5,1.12,1.38,0.75,0.75,1,1.5,0.75,3,2.25,3.75,2.5,2.5,2.75,1.75,3.25,2.38,3.38,2,1.88,0.62,0.5,1.38,0.38,1.62,1.62,1,1,1.75,1.62,1.25,0.62,1,2.12,1.12,1.12,1,1.75,3.12,1.25,1,2.75,1.62,3.12,1.88,0.62,3.25,1.88,2,2.38,1.25,2.12,0.5,2.38,2.25,2.25,3.75,1.62,2.25,1.12,3.62,0.88,1.38,4.12,2,1.5,1.88,4.12,0.75,0.88,1.75,4,1,1.88,1.75,0.88,4.25,2,4.38,3.5,1.62,3.62,0.75,3.5,2.75,1.88,3.12,0.38,3.12,4.25,2.25,2.12,1.38,2.62,3.62,3,4.12,0.5,2.25,1.12,1.38,1.38,1.88,2.62,2.38,4,4.12,0.88,1.5,4,2,1.25,3.25,1,1,1.62,2.12,1.88,1.38,3.25,2,1.88,1.25,2,2.12,1.62,0.75,2.12,0.88,1.12,1.62,2.38,1.25,3,1.38,1.62,1.88,0.5,3.38],[2.33,1.67,1,2.67,2.67,1,3.33,3.67,2.67,2.67,2,2.67,2.67,4.67,5,2.67,2,2,4.33,3.67,1.67,2,3.33,2.67,2.33,1.67,2.67,1.67,2,2.67,2,1.67,2.67,3.33,1.33,1.67,2.67,3,4,3,2.67,1.67,1.67,2,4.67,3,0.67,2.67,2,3.67,1.67,2.33,0.67,3.33,2,2.67,1.67,2.67,1,1.33,4,2.67,1.67,3.33,2.67,3.67,3,2.67,3,4.33,2,1.33,1.67,3.33,3,1.67,4,0,4,1,1.67,3,0.33,2.33,1,3.33,2.67,4,1.33,3.67,2.67,2,1,2.67,4.67,4,3.33,5.33,1.67,3.67,2.67,3.67,4.33,3.33,2.67,2.67,5.33,2.67,5.67,3.33,3.67,4.33,5,4,1,3.67,2.67,3,2.33,2.67,2.67,3.33,4,2.33,3.33,4.33,4.33,3.33,3,2,4.33,4,1.33,2,2.67,4,4.33,3.33,2.33,3.33,3.33,2,3.67,6,2.67,3.67,4,0.67,5.67,2.67,5,3,3,1.33,3,3,3.33,2.67,3.67,3,2.67,3.33,5.67,3.33,3.67,3,3.33,0.33,3.33,1.67,4.67,2.33,3.67,3.33,2.67,4.33,1.67,4.33,4.67,2.33,2.67,3,4.33,3,1.33,3,3,3,3,1.67,2.67,3,3,0.67,2,6.33,5,3,3,2.67,4.67,3.67,2,3.67,2.67,3.33,2.33,2.33,1.67,2,4.67,2.33,3,6,2.67,3.33,6,2.33,3,1.67,2,4.33,3.33,5,3,2.67,3,3.33,2.67,5,2.33,3,5,2.67,1.67,3,4.33,5.33,5,3,4.33,3.33,3.67,3.67,2.67,3.33,3.33,4,3.67,3,4,6,5,4,5.33,2.67,2.33,5.67,3.33,3.33,3.33,2,4,4.33,4.67,4,6,4.67,4.67,3.33,4.67,3.33,2.67,2.67,2.33,1.33,3,4,1.67,2.67,2.33,5,2.67,4,2.67,3.33,4.33,2.33,3,3.33,2.67,1.33,3.33,3.33,3,3,2.67,2.33,3.67,3.67,3.67],[5.75,3,1.75,4.5,4,3,6,4.25,5.75,5,3.5,4.5,4,4,5.5,4.25,4,2.5,5.25,3.75,2.5,3.25,5.75,3,3.75,3.5,2.25,3,3,3.25,3.5,3,5.25,4.25,3,4.75,4,3,5.25,5.25,4.25,4.25,3.75,3,5.5,4.25,1,3.25,2.25,5.5,2.25,4.5,1.5,3.5,4.5,4.5,3,5.5,2.5,3,5.5,5,2.5,4.5,5,4.5,3.75,2.75,2.5,4,3,2.25,2.75,5.75,3.25,2.25,4.75,1.5,3.25,1.5,2,4.75,2.25,3.5,1.5,5.75,4,5,1.25,4.5,2.75,3.75,2,3.25,4.75,4.25,5.75,6.75,2.75,4.5,3.25,3.75,4.5,4.5,5.75,5.5,5.75,2.75,5.5,3.5,4.75,4.25,3.5,5.25,2,4.75,4.75,2.75,2.25,3.25,4.25,3,6.5,3.75,5,4,5.5,5,6,2.75,6.25,4.25,2,3.75,5,6.25,5.75,5.25,4.5,5.75,5.75,1.5,5.25,6.5,5,5,5,2.5,5.5,3.75,5.75,5.5,4.25,2.25,2.5,4.75,4.25,4.25,4.75,4.75,6.25,5.75,6.25,4.5,5.25,5.25,4,1.75,2.75,2.5,5.5,3,5.75,5.75,4.25,6,4.25,6,6.5,3.25,4.25,5,4.75,2.75,4,4.75,4.25,5,3.5,3,3.75,5.75,5.5,1,4.5,6,5,5.75,3,4.5,4.25,5.75,2.5,4.75,5.5,5.5,4,5,1.75,4,7,5.25,5.25,6,4.5,4.25,6.5,4,4,1.5,3,4,4,4.75,4,3.75,3.5,4,4.25,6,3.25,4.75,6.25,3.25,2.75,4.75,6.25,6.25,5.75,5.75,5.5,6.25,5.75,6.5,4.25,4.75,5,5,6,5.25,5.75,6.5,5.75,4,6.25,4.75,4.75,6.5,4.75,5.25,6.25,6,4.75,5.75,5,6,6.75,5.5,5.5,3.75,5.25,4.75,4.75,4.75,3.75,3.25,4.75,4.75,2.75,4.5,4.75,6,4.5,5.25,3.5,4,6.25,4,4.75,4.75,5,3,4.25,4.5,3.25,4.25,4.25,4,5.75,4.5,5.75],[1.29,1.29,0.43,2.43,2.57,0.86,2.86,1.29,2.71,2.57,1.57,2.71,2.29,1.57,3,0.71,1.29,1.71,3.71,2.57,0.57,2.14,3.14,1,1.29,1.43,0.71,1.14,2,1.86,1.86,1,2,1.86,0.86,1.43,2,1.71,3.29,3.14,2.14,1.57,0.57,1.43,2,1.29,1,1.29,1,2.14,0.14,1.43,0.14,2.14,2.14,1.43,1.71,2.43,1.29,1,2.57,2.14,0.71,2.43,1.43,3,1,1.86,1.57,2.71,1,1.14,1.57,2.71,0.71,1,2.29,1.14,1.86,1.86,1.57,2.43,0.57,0.71,1,3.71,0.86,2.14,0.57,1.71,1.86,0.43,1.57,1.14,2.14,2.43,2.86,2.71,1.43,3.29,1,1.71,1.86,2.86,5,2.14,3.14,2,4,1.43,3,1.57,1.86,1.86,0.86,1.86,2.71,1,1.14,2,1.29,2,3.57,1.57,2.86,1.14,3,2.29,2.43,0.57,3.14,2.29,0.57,1.86,2.43,2.57,2.86,2.14,2.57,3,2.29,0.43,4.71,6.14,0.86,3,2.57,1.43,4.14,1,4.86,2.14,2.43,1.14,1.43,2.14,1.43,1.43,2.71,1.57,3.43,2.57,5.86,1.57,1.14,2.29,1.86,1.57,2,1.43,3.71,1.57,2.57,5,2.86,5.14,1.57,3.57,3.43,0.57,1.86,2.43,2.71,1,2.29,2.43,1.86,3,2.86,0.57,1.14,2.14,2.86,0.29,1.86,4.71,3.57,3.43,1.14,1.43,1.57,3.29,1.43,2.57,2.43,2.57,1.71,1.86,0.71,1.86,2.86,2,2.43,3.86,0.86,2.14,4.43,1,2.29,0.57,0.86,2.14,2.29,2.71,2,1.71,1.43,2.43,2.43,5.57,2.71,3.14,4.29,1.86,1.57,1.57,3.71,2.14,3,3.29,2.43,3.86,2.57,1.71,2.14,2.71,2.71,3.29,2.71,1.71,2.14,5.43,4.29,4.71,4.57,2.71,2.71,4.29,2.29,2.71,3.29,1.29,2.43,3.71,4.14,3.86,4.71,3.43,4.14,1.86,2,2.43,2.14,1.86,1.43,2.43,2,2.14,2.29,1.86,1.14,3.29,1.71,2.71,1.71,1.43,4.57,1.57,3.29,1.43,0.86,1.57,2,2,1.57,2.86,1,1,4.29,2,3.14],[3.39,3.78,3.26,3,3.7,4.35,4.7,3.39,4.52,4.13,3.74,3.7,5.87,5.13,4,4.09,3.7,4,3.91,3.48,2.61,4.48,3.48,5.83,4.7,5.74,4.13,2.83,5.13,4.65,4.83,2.04,2.7,5.39,2.78,3.13,3.83,4.09,5.52,3.22,4.91,2.83,3.96,3.96,5.39,4.83,3.35,6.13,5.65,2.57,2.35,3.65,3.26,3.48,4.17,4.04,4.17,3.43,3.39,3.52,5.26,4.91,2.65,5.52,3.3,5.7,3.61,3.87,6.83,4.74,3.61,3.74,5.26,3.48,3.48,3.13,5.65,5.7,5.57,4.7,5.87,5.13,5.35,5.78,4.96,4.61,4.09,5.52,3.57,4.17,6.65,5.39,3.57,3.61,4.13,3.57,5.52,5.13,5.57,4.91,4.26,4.52,5.87,3.83,3,6.35,7.43,4.17,5.7,4.48,3.26,2.87,4.57,4.7,3.57,4.83,5.3,5.57,3.7,4.09,5.83,4.61,3.74,3.65,5,4,5.13,4.91,3.3,4.52,4.57,7.26,4.91,4.7,3.43,4.39,3.35,4.43,6.26,6.43,6.04,3.3,3.83,5.35,2.39,5.61,6.96,4.52,3.57,5.13,5.65,5.78,5.39,5.39,4.7,3.61,3,2.83,2.17,4.96,4.87,4.09,5.61,4.17,4.48,3.87,3.83,4.48,3.61,4.3,2.13,2.83,2.87,3.13,4.13,3.57,4.61,3.83,4.87,5.48,2.96,3.22,4.17,2.39,3.52,2.22,2.26,4.7,3.52,2.17,4.35,2.43,3.52,1.3,4.04,4,4.13,2.52,2.83,2.65,3.57,2.7,2.65,3.09,2.65,3.7,2.78,4.13,2,3.74,3.83,3.87,4.35,3.48,3.17,3.48,5.22,2.91,4.61,4.39,1.87,3.17,3.17,4.39,5.39,3.91,3.87,5.13,2.96,3.52,2.96,3.83,2.96,2.43,3.3,5.65,3.65,4.74,4.74,6.48,4.87,4.48,5.83,3.7,4,4.78,3.65,4,5.74,5.78,6.04,5.78,4.17,5.13,3.48,3.39,4.43,5,4.13,2.96,3.78,4.35,4.83,3.39,5.09,4.17,6.3,4.3,4.22,5,4.61,3,5.87,3.7,4.74,4,3.39,3.57,4.61,3.65,3.48,2.39,3.35,2.78,4.26,3.48,3.35,5.87,5.22,2.43,5.83,4.17,5.48,3.39,4.17,3.04,5.09,4.61,4,5.09,4.09],[5.75,6.25,3.9,5.3,6.3,6.65,6.2,5.15,4.65,4.55,5.7,5.15,5.2,4.7,4.35,3.8,6.65,5.25,4.85,5.35,4.6,5.45,4.6,5.3,4.6,6.25,5.1,5.55,5.85,4.85,6.95,3.65,4.3,4.35,5.2,3.75,4,3.5,5.45,4.5,5.1,5.3,4.75,5.6,5,5,6.35,8,5.9,4.8,5.05,5.15,4.2,5.1,4.8,5.7,5.25,5.8,4.55,6.15,6.2,5.35,3.85,5.45,4.5,5.4,5.75,6.1,5.7,5.95,5.5,5.75,7.35,4.6,5.7,5.75,5.7,4,7.35,5.15,6.45,5.75,5.2,5.75,4.85,6.85,5.4,4.55,5.55,5.95,7.5,7.8,6.4,4.8,5.35,3.6,5.85,5.55,6.1,5.15,5.3,4.4,6.25,4.85,6.2,6.5,5.7,6.8,6.4,4.15,3.9,6,5.35,4.3,3.95,5.85,6.85,6.6,5.2,5.55,6.4,6.4,7.6,5.35,6.9,6.95,5.65,5.25,5.1,6.25,7.8,6.35,6,5.25,6,5.85,5.1,5.15,6.55,8.3,5.25,5.25,7.1,5.75,5.6,4.9,6.25,5,6.3,4.75,7.55,7.9,7.5,6.15,5.6,6.15,4.1,4.9,4.3,5.15,6.1,5.65,6.95,4.75,5.7,5.05,5.35,6.8,5.4,4.35,4.2,4,5.65,5.2,5.5,5.15,4,6.05,5.75,10,5.8,5.9,6.05,5.9,6.4,4.6,4.7,5.65,5.8,3.6,7.2,6.5,4.8,3.05,5.55,5.4,4.6,4.55,4.2,5,5.2,4.15,3.85,4.7,3.5,6.4,3.7,6.4,3.6,4.95,5.7,6.05,6.05,5.6,4.2,5.05,5.45,4.4,6.35,5.3,5,3.65,5.05,5.6,5.95,6.3,5.8,5.8,4.1,5.2,4.85,5.45,4.55,3.75,5.7,5.25,6.35,5.55,7.15,7.8,6.3,4.9,5.1,4.95,4.75,6.75,6.6,6.25,5.9,5.55,5.5,8.05,6.1,5.6,4.75,5.05,5.65,6.8,5.95,4,4.65,9.1,6.25,5.15,5.4,5.65,5.85,5.4,6,6.45,5.3,6.5,7.1,5.45,7,4.05,4.45,5.4,7.15,6.3,5.85,4,4.7,4.7,6.6,5.25,5.95,6.3,6.55,5.75,5.5,5.75,6,5.15,4.85,4.25,5.6,6.05,6,6.2,6.95],[6.36,7.92,4.42,4.86,5.92,7.5,4.86,3.67,7.36,4.36,4.31,4.14,5.86,4.44,5.86,5.14,5.25,5.44,5.75,4.92,5.39,7,5,6.78,4.14,4.33,4.53,4.42,8.61,5.44,5.97,3.36,4.81,5.64,4.83,4.92,5.31,5.08,5.11,4.89,4.64,4.78,2.78,6.67,6.86,5,6.28,5.44,6.06,5.53,5.5,4.78,5.39,4.19,4.42,5.56,5.64,4.75,4.83,3.94,6.14,4.78,5.33,5.83,5.03,6.31,6.19,4.25,3.92,5.42,4.61,5.17,5.97,4.28,4.58,4.67,6.47,5.64,5.75,5.33,6.03,5.31,5.78,4.97,4.58,5.47,5.97,5.14,4.89,6.67,5.44,6.11,5.72,3.94,3.78,5.44,4.22,7.22,4.61,5.75,6.25,6.58,4.11,4.83,6.03,6.17,5.19,7,7.53,3.36,4.86,5.44,5.44,6,6.33,5.42,5,6.44,5.17,5.44,6.86,3.31,6.5,4.78,6.39,5.67,4.92,4.97,5.78,6.31,7,7.19,4.81,3.72,6.17,6.11,5.44,4.56,6.89,7.08,6.22,5.72,5.78,6.61,5.97,3.86,6.31,4.75,5.47,5.22,6.17,6.94,5.42,5.19,4.14,4.69,4.33,5.42,6.33,4,4.44,5.58,9.25,4.83,5.47,4.94,3.81,4.28,5.58,4.08,4.75,3.47,5.17,6.17,4.47,5.69,3.28,6.25,5.14,6.56,6.08,5.31,5,4.94,5.25,5.06,3.97,5,4.42,4.5,5.69,5.5,5.53,3.11,5.14,4.11,4.94,4.81,3.81,5.94,6.78,3.97,4.42,4.28,3.33,5.61,4.58,3.81,3.36,5.94,6.19,6.17,5.72,6.36,4.47,5.14,5.69,5,4.86,4.78,4.03,3.61,6.11,3.22,6.11,6.72,6.56,7,4.72,5.83,4.14,5.31,5.03,4.92,4.33,6.69,6.39,5.56,6.83,6.86,6.31,4.67,6.22,5.25,5.97,5.53,4.08,6.44,5.19,6.53,5.53,6.92,5.89,3.67,4.75,4.97,5.83,7.39,6.67,3.47,4.72,6.31,5.72,5.5,6.58,5.72,6.28,5.97,7,5.08,5.19,5.5,6.25,6.11,4.94,4.17,5.31,5.06,5.56,5.97,6.53,4.28,3.75,5.25,6.67,5.69,5.42,5.67,5.72,5,6.78,4.83,4.5,6.33,5.78,5.67,5.25,6.08,7.61,4.39,5.17]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>id<\/th>\n      <th>sex<\/th>\n      <th>ageyr<\/th>\n      <th>agemo<\/th>\n      <th>school<\/th>\n      <th>grade<\/th>\n      <th>x1<\/th>\n      <th>x2<\/th>\n      <th>x3<\/th>\n      <th>x4<\/th>\n      <th>x5<\/th>\n      <th>x6<\/th>\n      <th>x7<\/th>\n      <th>x8<\/th>\n      <th>x9<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":4,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,6,7,8,9,10,11,12,13,14,15]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[4,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>

---

# Ejemplificación de caso

## 1. Especificación


```r
model &lt;-  " visual  =~ x1 + x2 + x3
            textual =~ x4 + x5 + x6
            speed   =~ x7 + x8 + x9 "
```

## 2. Identificación y Estimación
Almacenamos la estimación en el objeto `fit` sobre el cuál consultaremos para obtener información. 

*Recordar:* Es importante el almacenar información con `&lt;-`

```r
library(lavaan)
```

```
## This is lavaan 0.6-6
```

```
## lavaan is BETA software! Please report any bugs.
```

```r
fit &lt;- cfa(model = model,
           data  = HolzingerSwineford1939)
```

---

# Ejemplificación de caso

## 4. Evaluación

.scroll-output[

```r
summary(fit)
```

```
## lavaan 0.6-6 ended normally after 35 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of free parameters                         21
##                                                       
##   Number of observations                           301
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                85.306
##   Degrees of freedom                                24
##   P-value (Chi-square)                           0.000
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   visual =~                                           
##     x1                1.000                           
##     x2                0.554    0.100    5.554    0.000
##     x3                0.729    0.109    6.685    0.000
##   textual =~                                          
##     x4                1.000                           
##     x5                1.113    0.065   17.014    0.000
##     x6                0.926    0.055   16.703    0.000
##   speed =~                                            
##     x7                1.000                           
##     x8                1.180    0.165    7.152    0.000
##     x9                1.082    0.151    7.155    0.000
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   visual ~~                                           
##     textual           0.408    0.074    5.552    0.000
##     speed             0.262    0.056    4.660    0.000
##   textual ~~                                          
##     speed             0.173    0.049    3.518    0.000
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .x1                0.549    0.114    4.833    0.000
##    .x2                1.134    0.102   11.146    0.000
##    .x3                0.844    0.091    9.317    0.000
##    .x4                0.371    0.048    7.779    0.000
##    .x5                0.446    0.058    7.642    0.000
##    .x6                0.356    0.043    8.277    0.000
##    .x7                0.799    0.081    9.823    0.000
##    .x8                0.488    0.074    6.573    0.000
##    .x9                0.566    0.071    8.003    0.000
##     visual            0.809    0.145    5.564    0.000
##     textual           0.979    0.112    8.737    0.000
##     speed             0.384    0.086    4.451    0.000
```
]

---

# Ejemplificación de caso

## 4. Evaluación

.scroll-output[

```r
summary(fit, fit.measures = TRUE, standardized = TRUE)
```

```
## lavaan 0.6-6 ended normally after 35 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of free parameters                         21
##                                                       
##   Number of observations                           301
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                85.306
##   Degrees of freedom                                24
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                               918.852
##   Degrees of freedom                                36
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.931
##   Tucker-Lewis Index (TLI)                       0.896
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -3737.745
##   Loglikelihood unrestricted model (H1)      -3695.092
##                                                       
##   Akaike (AIC)                                7517.490
##   Bayesian (BIC)                              7595.339
##   Sample-size adjusted Bayesian (BIC)         7528.739
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.092
##   90 Percent confidence interval - lower         0.071
##   90 Percent confidence interval - upper         0.114
##   P-value RMSEA &lt;= 0.05                          0.001
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.065
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   visual =~                                                             
##     x1                1.000                               0.900    0.772
##     x2                0.554    0.100    5.554    0.000    0.498    0.424
##     x3                0.729    0.109    6.685    0.000    0.656    0.581
##   textual =~                                                            
##     x4                1.000                               0.990    0.852
##     x5                1.113    0.065   17.014    0.000    1.102    0.855
##     x6                0.926    0.055   16.703    0.000    0.917    0.838
##   speed =~                                                              
##     x7                1.000                               0.619    0.570
##     x8                1.180    0.165    7.152    0.000    0.731    0.723
##     x9                1.082    0.151    7.155    0.000    0.670    0.665
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   visual ~~                                                             
##     textual           0.408    0.074    5.552    0.000    0.459    0.459
##     speed             0.262    0.056    4.660    0.000    0.471    0.471
##   textual ~~                                                            
##     speed             0.173    0.049    3.518    0.000    0.283    0.283
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .x1                0.549    0.114    4.833    0.000    0.549    0.404
##    .x2                1.134    0.102   11.146    0.000    1.134    0.821
##    .x3                0.844    0.091    9.317    0.000    0.844    0.662
##    .x4                0.371    0.048    7.779    0.000    0.371    0.275
##    .x5                0.446    0.058    7.642    0.000    0.446    0.269
##    .x6                0.356    0.043    8.277    0.000    0.356    0.298
##    .x7                0.799    0.081    9.823    0.000    0.799    0.676
##    .x8                0.488    0.074    6.573    0.000    0.488    0.477
##    .x9                0.566    0.071    8.003    0.000    0.566    0.558
##     visual            0.809    0.145    5.564    0.000    1.000    1.000
##     textual           0.979    0.112    8.737    0.000    1.000    1.000
##     speed             0.384    0.086    4.451    0.000    1.000    1.000
```
]

---

## 5. Re-Especificación


```r
modindices(fit, sort = TRUE, maximum.number = 10)  
```

```
##        lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox
## 30  visual =~  x9 36.411  0.577   0.519    0.515    0.515
## 76      x7 ~~  x8 34.145  0.536   0.536    0.859    0.859
## 28  visual =~  x7 18.631 -0.422  -0.380   -0.349   -0.349
## 78      x8 ~~  x9 14.946 -0.423  -0.423   -0.805   -0.805
## 33 textual =~  x3  9.151 -0.272  -0.269   -0.238   -0.238
## 55      x2 ~~  x7  8.918 -0.183  -0.183   -0.192   -0.192
## 31 textual =~  x1  8.903  0.350   0.347    0.297    0.297
## 51      x2 ~~  x3  8.532  0.218   0.218    0.223    0.223
## 59      x3 ~~  x5  7.858 -0.130  -0.130   -0.212   -0.212
## 26  visual =~  x5  7.441 -0.210  -0.189   -0.147   -0.147
```


---
class: inverse, center, middle

# .font120[**Fiabilidad por consistencia interna**]

---

# Fiabilidad por consistencia interna
* ### Problemática de Alfa y la tau-equivalencia
* ### Procedimiento en software

---
class: inverse, center, middle

# .font120[**Gracias**]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "foundation",
"highlightLines": true,
"countIncrementalSli des": false,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
